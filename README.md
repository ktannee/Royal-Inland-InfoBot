# Royal-Inland-InfoBot
A Retrieval-Augmented Generation (RAG) powered chatbot that answers questions using hospital/organization-specific documents.
This demo project uses LangChain, FAISS/Chroma, and Streamlit to make hospital information accessible through natural conversation.

ğŸ“‚ Project Structure
<pre lang="text"><code> ğŸ“ royal-inland-infobot/ 
  â”œâ”€â”€ data/ 
  â”‚ â””â”€â”€ hospital_docs/ 
    â””â”€â”€ chunks.pkl 
  â”œâ”€â”€ app/ 
  â”‚ â”œâ”€â”€ chatbot_app.py 
  â”‚ â””â”€â”€ data_loader.py 
    â””â”€â”€embeddings.py 
    â””â”€â”€rag_pipeline.py 
  â”œâ”€â”€ requirements.txt 
  â””â”€â”€ README.md </code></pre>


The MVP includes:

âœ”ï¸ Fully open source stack with no API keys needed

âœ”ï¸ Local embeddings + FAISS retrieval

âœ”ï¸ A small system prompt to reduce hallucinations

âœ”ï¸ Source snippets shown for transparency

âœ”ï¸ Easy to extend PDFs/HTML and many more pages


<img width="1006" height="531" alt="Screenshot 2025-08-25 at 5 05 40â€¯PM" src="https://github.com/user-attachments/assets/33f09927-7f27-466a-82e1-0ba111a74e1e" />

1ï¸âƒ£ Clone the Repository
`git clone https://github.com/ktannee/royal-inland-infobot.git
cd royal-inland-infobot`

2ï¸âƒ£ âš™ï¸ Environment Setup
`pip install -r requirements.txt`

3ï¸âƒ£ ğŸ—‚ï¸ **Data Preparation**
This project does not include the data/ folder (for privacy reasons).
However, you can collect your own documents and use them to reproduce the pipeline.

**1. Collect Your Data**
Download hospital or organization documents (e.g., service descriptions, FAQs, annual reports, policies, PDFs, or web pages).
Place them inside:


```data/
|   â””â”€â”€ hospital_docs/
|      â”œâ”€â”€ file1.pdf
|      â”œâ”€â”€ file2.html
|      â””â”€â”€ ...

You can use:
- PDFs (brochures, reports, guidelines)
- HTML pages (download with wget or BeautifulSoup)
- Plain text files

**2. Process and Chunk Data**
The script app/data_loader.py automatically:
Reads all files in data/hospital_docs/
Cleans and chunks the text into manageable sections
Saves the chunks to data/chunks.pkl

**3. Build Vector Store**
The embeddings are created from your chunks and stored in a vector database (FAISS/Chroma).
This makes the RAG pipeline able to retrieve context when answering user queries.

**4. Run the Chatbot**
Once your data is prepared, launch the Streamlit app:
`streamlit run app/chatbot_app.py`

This will start an interactive chatbot where you can query your own hospital/organization data.


